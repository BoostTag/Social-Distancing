{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import Darknet\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import imutils\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location and name of the cfg file\n",
    "cfg_file = '/Users/mayurjain/darknet/cfg/yolov3.cfg'\n",
    "\n",
    "# Set the location and name of the pre-trained weights file\n",
    "weight_file = '/Users/mayurjain/darknet/yolov3.weights'\n",
    "\n",
    "# Set the location and name of the COCO object classes file\n",
    "namesfile = '/Users/mayurjain/darknet/data/coco.names'\n",
    "\n",
    "# Load the network architecture\n",
    "m = Darknet(cfg_file)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "m.load_weights(weight_file)\n",
    "\n",
    "# Load the COCO object classes\n",
    "class_names = load_class_names(namesfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [24.0, 14.0]\n",
    "IMAGE = '/Users/mayurjain/Computer VIsion Nanodegree/Social DIstancing Using Deep Learning and OpenCV/peaky_blinders.png'\n",
    "# Load the image\n",
    "img = cv2.imread(IMAGE)\n",
    "\n",
    "# Convert the image to RGB\n",
    "original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# We resize the image to the input width and height of the first layer of the network.    \n",
    "resized_image = cv2.resize(original_image, (m.width, m.height))\n",
    "\n",
    "# Display the images\n",
    "plt.subplot(121)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(original_image)\n",
    "plt.subplot(122)\n",
    "plt.title('Resized Image')\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_thresh = 0.6\n",
    "iou_thresh = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [15.0, 7.0]\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(IMAGE)\n",
    "\n",
    "# Convert the image to RGB\n",
    "original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# We resize the image to the input width and height of the first layer of the network.    \n",
    "resized_image = cv2.resize(original_image, (m.width, m.height))\n",
    "\n",
    "# Set the IOU threshold. Default value is 0.4\n",
    "iou_thresh = 0.4\n",
    "\n",
    "# Set the NMS threshold. Default value is 0.6\n",
    "nms_thresh = 0.6\n",
    "\n",
    "# Detect objects in the image\n",
    "boxes = detect_objects(m, resized_image, iou_thresh, nms_thresh)\n",
    "\n",
    "# Print the objects found and the confidence level\n",
    "print_objects(boxes, class_names)\n",
    "\n",
    "#Plot the image with bounding boxes and corresponding object class labels\n",
    "plot_boxes(original_image, boxes, class_names, plot_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Detected_BB = \"/Users/mayurjain/Computer VIsion Nanodegree/Social DIstancing Using Deep Learning and OpenCV/pea.png\"\n",
    "image = cv2.imread(IMAGE)\n",
    "box_measures = defaultdict(dict)\n",
    "width = img.shape[1]\n",
    "height = img.shape[0]\n",
    "colors = ((0, 0, 255), (240, 0, 159), (0, 165, 255), (255, 255, 0),(255, 0, 255))\n",
    "for i, box in enumerate(boxes):    \n",
    "    x1 = int(np.around((box[0] - box[2]/2.0) * width))\n",
    "    y1 = int(np.around((box[1] - box[3]/2.0) * height))\n",
    "    x2 = int(np.around((box[0] + box[2]/2.0) * width))\n",
    "    y2 = int(np.around((box[1] + box[3]/2.0) * height))\n",
    "\n",
    "    if x2-x1 > 50:\n",
    "        box_measures[\"box\"+str(i)] = {\"top_left\": (x1, y1), \"top_right\": (x2, y1),\"bottom_right\": (x2, y2),\n",
    "                                  \"bottom_left\": (x1, y2), \"center\": (int((x1+x2)/2),int((y1+y2)/2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = []\n",
    "count = 0\n",
    "box_array = np.zeros((4,2),dtype=int)\n",
    "for key,v in box_measures.items():\n",
    "    for i, (k,v) in enumerate(box_measures[key].items()):\n",
    "        if i ==4:\n",
    "            center.append((np.average(box_array[:, 0]), np.average(box_array[:, 1])))\n",
    "            break\n",
    "        box_array[i,count], box_array[i, count+1] = v[0],v[1]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ((0, 0, 255), (240, 0, 159), (0, 165, 255), (255, 255, 0),(255, 0, 255))\n",
    "box0_array = np.zeros((4,2),dtype=int)\n",
    "count = 0\n",
    "refObj = None\n",
    "for key,v in box_measures.items():\n",
    "    for i, (k,v) in enumerate(box_measures[key].items()):\n",
    "        if i ==4:\n",
    "            break\n",
    "        box0_array[i,count], box0_array[i, count+1] = v[0],v[1]\n",
    "        \n",
    "    cX = np.average(box0_array[:, 0])\n",
    "    cY = np.average(box0_array[:, 1])\n",
    "    if refObj is None:\n",
    "        # unpack the ordered bounding box, then compute the\n",
    "        # midpoint between the top-left and top-right points,\n",
    "        # followed by the midpoint between the top-right and\n",
    "        # bottom-right\n",
    "        (tl, tr, br, bl) = box0_array\n",
    "        (tlblX, tlblY) = midpoint(tl, bl)\n",
    "        (trbrX, trbrY) = midpoint(tr, br)\n",
    "        # compute the Euclidean distance between the midpoints,\n",
    "        # then construct the reference object\n",
    "        D = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "        refObj = (box0_array, (cX, cY), D / 0.70)\n",
    "        continue\n",
    "    # draw the contours on the image\n",
    "    orig = image.copy()\n",
    "    \n",
    "    # stack the reference coordinates and the object coordinates\n",
    "    # to include the object center\n",
    "    refCoords = np.vstack([refObj[0], refObj[1]])\n",
    "    objCoords = np.vstack([box0_array, (cX, cY)])\n",
    "    cv2.rectangle(orig, (refObj[0][0][0], refObj[0][0][1]),\n",
    "                  (refObj[0][2][0], refObj[0][2][1]), (0, 255, 0), 2)    \n",
    "    cv2.circle(orig, (int(refObj[1][0]), int(refObj[1][1])), 5, colors[0], -1)\n",
    "    cv2.circle(orig, (int(cX), int(cY)), 5, colors[0], -1)\n",
    "    cv2.line(orig, (int(refObj[1][0]), int(refObj[1][1])), (int(cX), int(cY)), colors[0], 2)\n",
    "\n",
    "    \n",
    "    D = dist.euclidean((refObj[1][0], refObj[1][1]), (cX, cY)) / refObj[2]\n",
    "    (mX, mY) = midpoint((refObj[1][0], refObj[1][1]), (cX, cY))\n",
    "    \n",
    "    if D > 1.8: #Success\n",
    "        cv2.putText(orig, \"{:.1f}m\".format(D), (int(mX), int(mY - 15)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, colors[1], 2)\n",
    "        \n",
    "        cv2.putText(orig, \"Social Distance Maintained\", (int(mX), int(mY + 15)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, colors[1], 2)\n",
    "    else:\n",
    "        cv2.putText(orig, \"{:.1f}m\".format(D), (int(mX), int(mY - 15)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, colors[0], 2)\n",
    "        \n",
    "        cv2.putText(orig, \"No Social Distance Maintained\", (int(mX), int(mY + 15)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, colors[0], 2)\n",
    "        \n",
    "    # show the output image\n",
    "    cv2.rectangle(orig, box_measures[key][\"top_left\"], box_measures[key][\"bottom_right\"],(255,0,0), 2)\n",
    "    cv2.imshow(\"Image\", orig)\n",
    "    cv2.imwrite(\"image_\"+key+\".png\", orig)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    " \n",
    "img_array = []\n",
    "each_image_duration = 30\n",
    "filenames = [ filename for filename in glob.glob(\"/Users/mayurjain/Computer Vision Nanodegree/Social_Distancing/images/*.png\")]\n",
    "filenames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "for filename in filenames:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    " \n",
    " \n",
    "out = cv2.VideoWriter('Social_Distancing.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    for _ in range(each_image_duration):\n",
    "        out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
